{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850cea44",
   "metadata": {},
   "source": [
    "# Dataset preprocessing\n",
    "\n",
    "### 1. Overview\n",
    "\n",
    "This notebook performs all dataset loading and preprocessing steps once, producing a clean and reproducible dataset split that will be reused by both the autoencoder-based IDS and the transformer-based IDS. This ensures a fair and controlled comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4be50",
   "metadata": {},
   "source": [
    "### 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d75ddb",
   "metadata": {},
   "source": [
    "### 3. Dataset Loading and Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69265ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 CSV files\n",
      "Loading dataset/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Loading dataset/Monday-WorkingHours.pcap_ISCX.csv\n",
      "Loading dataset/Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Loading dataset/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Loading dataset/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Loading dataset/Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Loading dataset/Wednesday-workingHours.pcap_ISCX.csv\n",
      "Loading dataset/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Merged dataset shape: (2830743, 79)\n",
      "Column types distribution:\n",
      " int64      54\n",
      "float64    24\n",
      "object      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = \"dataset\"\n",
    "\n",
    "csv_files = [\n",
    "    os.path.join(DATASET_DIR, f)\n",
    "    for f in os.listdir(DATASET_DIR)\n",
    "    if f.endswith(\".csv\")\n",
    "]\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "dfs = []\n",
    "for f in csv_files:\n",
    "    print(f\"Loading {f}\")\n",
    "    df_part = pd.read_csv(f)\n",
    "    dfs.append(df_part)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Merged dataset shape:\", df.shape)\n",
    "print(\"Column types distribution:\\n\", df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3f787",
   "metadata": {},
   "source": [
    "### 4. Column Cleanup\n",
    "\n",
    "Remove leading/trailing spaces and drop non-feature identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "011a4a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining columns: 78\n"
     ]
    }
   ],
   "source": [
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "DROP_COLS = [\n",
    "    \"Flow ID\",\n",
    "    \"Source IP\", \"Source Port\",\n",
    "    \"Destination IP\", \"Destination Port\",\n",
    "    \"Timestamp\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in DROP_COLS if c in df.columns])\n",
    "print(\"Remaining columns:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42553819",
   "metadata": {},
   "source": [
    "### 5. Handle NaN and Infinite Values\n",
    "\n",
    "CICIDS2017 contains undefined flow statistics (e.g., division by zero). These rows are removed following common practice in DL-based IDS studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e0657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN or Inf: 2867\n",
      "Cleaned dataset shape: (2827876, 78)\n"
     ]
    }
   ],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "bad_rows = df.isna().any(axis=1).sum()\n",
    "print(f\"Rows with NaN or Inf: {bad_rows}\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "print(\"Cleaned dataset shape:\", df.shape)\n",
    "\n",
    "# Check for non-numeric features\n",
    "assert X.select_dtypes(include=[\"object\"]).empty, \"Non-numeric feature detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8493d8",
   "metadata": {},
   "source": [
    "### 6. Label Processing\n",
    "\n",
    "Convert labels to binary form: BENIGN = 0, ATTACK = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea4602f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    2271320\n",
      "1     556556\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df[\"Label\"] = df[\"Label\"].apply(lambda x: 0 if x == \"BENIGN\" else 1)\n",
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27093f",
   "metadata": {},
   "source": [
    "### 7. Featureâ€“Label Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "497e3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\"])\n",
    "y = df[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3d5135",
   "metadata": {},
   "source": [
    "### 8. Train / Validation / Test Split\n",
    "\n",
    "A fixed split is used to support fair model comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a0ea4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1979513, 77)\n",
      "Validation shape: (424181, 77)\n",
      "Test shape: (424182, 77)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8100073",
   "metadata": {},
   "source": [
    "### 9. Feature Scaling\n",
    "\n",
    "StandardScaler is used to scale the features to have zero mean and unit variance.  \n",
    "The scaler is fitted only on the training data and reused across all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15e1ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3c79c",
   "metadata": {},
   "source": [
    "### 10. Save Processed Artifacts\n",
    "\n",
    "All outputs are saved and reused by subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f655c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processed/scaler.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"processed\", exist_ok=True)\n",
    "\n",
    "pd.DataFrame(X_train_scaled).to_csv(\"processed/X_train.csv\", index=False)\n",
    "pd.DataFrame(X_val_scaled).to_csv(\"processed/X_val.csv\", index=False)\n",
    "pd.DataFrame(X_test_scaled).to_csv(\"processed/X_test.csv\", index=False)\n",
    "\n",
    "y_train.to_csv(\"processed/y_train.csv\", index=False)\n",
    "y_val.to_csv(\"processed/y_val.csv\", index=False)\n",
    "y_test.to_csv(\"processed/y_test.csv\", index=False)\n",
    "\n",
    "joblib.dump(scaler, \"processed/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402f6af7",
   "metadata": {},
   "source": [
    "### 11. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82c38ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_samples    2.827876e+06\n",
       "train_samples    1.979513e+06\n",
       "val_samples      4.241810e+05\n",
       "test_samples     4.241820e+05\n",
       "benign_ratio     8.031894e-01\n",
       "attack_ratio     1.968106e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = {\n",
    "    \"total_samples\": len(df),\n",
    "    \"train_samples\": len(y_train),\n",
    "    \"val_samples\": len(y_val),\n",
    "    \"test_samples\": len(y_test),\n",
    "    \"benign_ratio\": (y == 0).mean(),\n",
    "    \"attack_ratio\": (y == 1).mean()\n",
    "}\n",
    "\n",
    "pd.Series(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2c55c",
   "metadata": {},
   "source": [
    "### 12. Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f058cbe6",
   "metadata": {},
   "source": [
    "The processed/ directory now contains all cleaned, scaled, and split data required for both IDS implementations. Subsequent notebooks must not perform additional preprocessing steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
